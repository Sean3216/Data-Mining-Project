{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a66ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_privacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "from tensorflow.keras.regularizers import L1,L2\n",
    "from tensorflow.keras import layers\n",
    "from keras import backend as K\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72d49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_data, train_labels = train\n",
    "test_data, test_labels = test\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32)/255\n",
    "test_data = np.array(test_data, dtype=np.float32)/255\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0],28,28,1) # angka 1 dibelakang menunjukkan color channel. Hanya ada 1 color channel\n",
    "test_data = test_data.reshape(test_data.shape[0],28,28,1)\n",
    "\n",
    "train_labels = np.array(train_labels, dtype = np.int32)\n",
    "test_labels = np.array(test_labels, dtype = np.int32)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes = 10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes = 10)\n",
    "\n",
    "#check data distribution, normalized since divided by 255\n",
    "assert train_data.min() == 0\n",
    "assert train_data.max() == 1\n",
    "assert test_data.min() == 0\n",
    "assert test_data.max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ad358",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2968b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_sgd(l2_norm_clip,noise_multiplier,num_microbatches,learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16,8,\n",
    "                              strides = 2,\n",
    "                              padding = 'same',\n",
    "                              activation = 'relu',\n",
    "                              input_shape = (28,28,1)),\n",
    "        tf.keras.layers.MaxPool2D(2,1),\n",
    "        tf.keras.layers.Conv2D(32,4,\n",
    "                               strides = 2,\n",
    "                               padding = 'valid',\n",
    "                               activation = 'relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,1),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tensorflow_privacy.DPKerasSGDOptimizer(\n",
    "        l2_norm_clip = l2_norm_clip,\n",
    "        noise_multiplier = noise_multiplier,\n",
    "        num_microbatches = num_microbatches,\n",
    "        learning_rate = learning_rate)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits = False, reduction = tf.losses.Reduction.NONE)\n",
    "    model.compile(optimizer = optimizer , loss = loss, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def getlayeroutput(model,data,index):\n",
    "    from keras import backend as K\n",
    "    getoutput = K.function([model.layers[0].input],[model.layers[index].output])\n",
    "    return getoutput([data])[0]\n",
    "\n",
    "def discriminator(in_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(in_shape*20,input_dim = in_shape,\n",
    "                              activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.6),\n",
    "        tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "    ])\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 0.001,\n",
    "    decay_steps = 200,\n",
    "    decay_rate = 0.96,\n",
    "    staircase = True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer,\n",
    "                 metrics = 'accuracy')\n",
    "    return model\n",
    "\n",
    "def discriminator(in_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(in_shape*20,input_dim = in_shape,\n",
    "                              activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.6),\n",
    "        tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "    ])\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 0.001,\n",
    "    decay_steps = 200,\n",
    "    decay_rate = 0.96,\n",
    "    staircase = True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer,\n",
    "                 metrics = 'accuracy')\n",
    "    return model\n",
    "\n",
    "def discriminatortrue(in_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(in_shape*1.25,input_dim = in_shape,\n",
    "                              activation = 'linear'),\n",
    "        tf.keras.layers.Dense(in_shape*2,activation = 'relu'),\n",
    "        tf.keras.layers.Dense(in_shape*1.5,activation = 'linear'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(in_shape*2,activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer,\n",
    "                 metrics = 'accuracy')\n",
    "    return model\n",
    "\n",
    "def generator(in_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        #tf.keras.layers.Dense(16,input_dim = in_shape),\n",
    "        tf.keras.layers.Conv1D(10,2,activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Conv1D(20,2,activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Conv1D(30,2,activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(25,activation='linear'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(10,activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(in_shape,activation='relu'),\n",
    "    ])\n",
    "    return model\n",
    "    \n",
    "def GAN(gen,dis):\n",
    "    dis.trainable = False\n",
    "    model = tf.keras.Sequential([ \n",
    "        gen,\n",
    "        dis\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss='binary_crossentropy',optimizer=opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_fake_samples(gen, data, batch):\n",
    "    x_input = np.random.randn(batch,data.shape[1])\n",
    "    x_input = np.expand_dims(x_input, axis=2)\n",
    "    x = gen.predict(x_input)\n",
    "    y = np.zeros((batch,1))\n",
    "    \n",
    "    return x.reshape(batch,data.shape[1]),y\n",
    "\n",
    "def shuffledata(xdata,ydata):\n",
    "    indices = tf.range(start=0,limit=tf.shape(xdata)[0], dtype = tf.int32)\n",
    "    idx = tf.random.shuffle(indices)\n",
    "    return tf.gather(xdata,idx) , tf.gather(ydata,idx)\n",
    "\n",
    "def train(gen, dis, distrue, gan, output_noise, output_true, n_epochs= 10000, n_batch = 512):\n",
    "    #determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch/2)\n",
    "    dishist=[]\n",
    "    genhist=[]\n",
    "    disacchist = []\n",
    "    distrueacchist = []\n",
    "    \n",
    "    ### HUGE NOTE: Normalmodel is 1, DPmodel is 0\n",
    "    \n",
    "    #train the true discriminator to the DPmodel and Normalmodel data\n",
    "    distrue_output_true_train_x = output_true[:] #setting x data from normalmodel for true discriminant\n",
    "    distrue_output_true_train_y = np.ones((output_true.shape[0],1)) #setting y data from normalmodel for true discriminant\n",
    "    \n",
    "    distrue_output_noise_train_x = output_noise[:] #setting x data from DPmodel for true discriminant\n",
    "    distrue_output_noise_train_y = np.zeros((output_noise.shape[0],1)) #setting y data from DPmodel for true discriminant\n",
    "    \n",
    "    #combine\n",
    "    distruex = pd.DataFrame(distrue_output_true_train_x).append(pd.DataFrame(distrue_output_noise_train_x),ignore_index = True).to_numpy()\n",
    "    distruey = pd.DataFrame(distrue_output_true_train_y).append(pd.DataFrame(distrue_output_noise_train_y),ignore_index = True).to_numpy()\n",
    "    \n",
    "    #shuffle\n",
    "    distruex_shuffle, distruey_shuffle = shuffledata(distruex,distruey)\n",
    "    distrue.fit(distruex_shuffle,distruey_shuffle)\n",
    "    \n",
    "    #manually enumerate epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        ###########################################################################################################      \n",
    "        ##GAN PART\n",
    "        #prepare samples      \n",
    "        #Normalmodel data\n",
    "        x_real = output_true[np.random.choice(output_true.shape[0], half_batch, replace=False), :]\n",
    "        y_real = np.ones((half_batch,1))\n",
    "        \n",
    "        #Normalmodel data upsampled (fake)\n",
    "        x_fake, y_fake = generate_fake_samples(gen, output_true, half_batch)\n",
    "        \n",
    "        #combined\n",
    "        disx = pd.DataFrame(x_real).append(pd.DataFrame(x_fake),ignore_index = True).to_numpy()\n",
    "        disy = pd.DataFrame(y_real).append(pd.DataFrame(y_fake),ignore_index = True).to_numpy()\n",
    "        \n",
    "        #shuffle\n",
    "        disx_shuffle, disy_shuffle = shuffledata(disx,disy)\n",
    "        \n",
    "        #update discriminator\n",
    "        disloss, disacc = dis.train_on_batch(disx_shuffle,disy_shuffle)\n",
    "        \n",
    "        #input for gan\n",
    "        noise = np.random.randn(n_batch,output_true.shape[1])\n",
    "        noise = np.expand_dims(noise, axis=2)\n",
    "        y_gen = np.ones((n_batch,1))\n",
    "        \n",
    "        #update generator from discriminator error\n",
    "        gen_loss_fake = gan.train_on_batch(noise,y_gen)\n",
    "        \n",
    "        ###########################################################################################################\n",
    "        ##TRUE DISCRIMINANT PART\n",
    "        #Check the true discriminator performance\n",
    "        #Normalmodel data upsampled (fake)\n",
    "        distrue_output_true_x = x_fake[:]\n",
    "        distrue_output_true_y = y_fake[:]\n",
    "        distrue_output_true_y[:] = 1\n",
    "    \n",
    "        #DPmodel data\n",
    "        distrue_output_noise_x = output_noise[np.random.choice(output_noise.shape[0], half_batch, replace=False), :]\n",
    "        distrue_output_noise_y = np.zeros((distrue_output_true_y.shape[0],0))\n",
    "        \n",
    "        #aggregated\n",
    "        distruex_test = pd.DataFrame(distrue_output_true_x).append(pd.DataFrame(distrue_output_noise_x),ignore_index = True).to_numpy()\n",
    "        distruey_test = pd.DataFrame(distrue_output_true_y).append(pd.DataFrame(distrue_output_noise_y),ignore_index = True).to_numpy()\n",
    "        \n",
    "        \n",
    "        distrueloss, distrueacc = distrue.test_on_batch(distruex_test,distruey_test)\n",
    "        \n",
    "        print('>%d, discriminant_loss=%.3f discriminant_acc=%.3f generator_loss=%.3f true_discriminant_acc=%.3f' % (epoch+1, disloss, disacc, gen_loss_fake, distrueacc))\n",
    "        \n",
    "        dishist.append(disloss)\n",
    "        genhist.append(gen_loss_fake)\n",
    "        disacchist.append(disacc)\n",
    "        distrueacchist.append(distrueacc)\n",
    "    plot_history(dishist,genhist,disacchist,distrueacchist)\n",
    "    \n",
    "    #final accuracy of True Discriminant\n",
    "    output_true_upsampled_x, output_true_upsampled_y = generate_fake_samples(gen, output_true, output_true.shape[0])\n",
    "    output_true_upsampled_y[:] = 1\n",
    "    \n",
    "    output_noise_x, output_noise_y = output_noise[:], np.zeros((output_noise.shape[0],1))\n",
    "    \n",
    "    distruex_final = pd.DataFrame(output_true_upsampled_x).append(pd.DataFrame(output_noise_x),ignore_index = True).to_numpy()\n",
    "    distruey_final = pd.DataFrame(output_true_upsampled_y).append(pd.DataFrame(output_noise_y),ignore_index = True).to_numpy()\n",
    "    \n",
    "    #shuffle\n",
    "    distruex_final_shuffle, distruey_final_shuffle = shuffledata(distruex_final,distruey_final)\n",
    "    \n",
    "    fin_loss, fin_acc = distrue.test_on_batch(distruex_final_shuffle, distruey_final_shuffle)\n",
    "    \n",
    "    print(\"Final True Discriminant Accuracy: %.3f\" % fin_acc)\n",
    "        \n",
    "        \n",
    "def plot_history(d_hist, g_hist, dacc_hist, dacc2_hist):\n",
    "    # plot loss    \n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(d_hist, label='discriminator_loss')\n",
    "    plt.plot(g_hist, label='generator_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(dacc_hist, label='GAN_discriminator_accuracy')\n",
    "    plt.plot(dacc2_hist, label='True_discriminator_accuracy')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64c14f",
   "metadata": {},
   "source": [
    "## Training Original Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f5ca23",
   "metadata": {},
   "source": [
    "##### DPmodel & Normalmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45a8a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "240/240 [==============================] - 39s 132ms/step - loss: 1.1429 - accuracy: 0.6526 - val_loss: 1.2173 - val_accuracy: 0.7374\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 30s 126ms/step - loss: 1.3376 - accuracy: 0.7543 - val_loss: 1.3906 - val_accuracy: 0.7351\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 30s 125ms/step - loss: 1.3964 - accuracy: 0.7087 - val_loss: 1.3229 - val_accuracy: 0.7082\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 30s 125ms/step - loss: 1.4388 - accuracy: 0.6870 - val_loss: 1.2392 - val_accuracy: 0.7103\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 30s 127ms/step - loss: 1.3609 - accuracy: 0.6710 - val_loss: 1.2486 - val_accuracy: 0.6971\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 33s 128ms/step - loss: 0.7731 - accuracy: 0.7581 - val_loss: 0.4271 - val_accuracy: 0.8859\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 30s 126ms/step - loss: 0.4367 - accuracy: 0.8986 - val_loss: 0.4281 - val_accuracy: 0.9099\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 30s 126ms/step - loss: 0.5176 - accuracy: 0.9034 - val_loss: 0.5701 - val_accuracy: 0.9080\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 34s 142ms/step - loss: 0.7270 - accuracy: 0.9008 - val_loss: 0.7685 - val_accuracy: 0.9024\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 37s 152ms/step - loss: 0.8864 - accuracy: 0.8955 - val_loss: 0.8716 - val_accuracy: 0.8999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9c2aa52e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPmodel = dp_sgd(l2_norm_clip = 1.5, noise_multiplier = 1.8, \n",
    "                 num_microbatches = 50, learning_rate = 0.25)\n",
    "Normalmodel = dp_sgd(l2_norm_clip = 1.5, noise_multiplier = 1, \n",
    "                 num_microbatches = 50, learning_rate = 0.25)\n",
    "\n",
    "DPmodel.fit(train_data, train_labels, \n",
    "            epochs = 5, batch_size = 250,\n",
    "            validation_data = (test_data, test_labels))\n",
    "\n",
    "Normalmodel.fit(train_data, train_labels, \n",
    "                epochs = 5, batch_size = 250,\n",
    "                validation_data = (test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e61a36",
   "metadata": {},
   "source": [
    "##### DP Model Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34123ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.417% and noise_multiplier = 1.6 iterated over 1200 steps satisfies differential privacy with eps = 0.422 and delta = 1e-05.\n",
      "The optimal RDP order is 27.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4223191547406633, 27.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=train_data.shape[0],\n",
    "                                              batch_size=250,\n",
    "                                              noise_multiplier=1.6,\n",
    "                                              epochs=5,\n",
    "                                              delta=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd56969",
   "metadata": {},
   "source": [
    "##### Normal Model Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890c6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.417% and noise_multiplier = 1 iterated over 1200 steps satisfies differential privacy with eps = 1.13 and delta = 1e-05.\n",
      "The optimal RDP order is 10.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.1278495014370558, 10.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=train_data.shape[0],\n",
    "                                              batch_size=250,\n",
    "                                              noise_multiplier=1,\n",
    "                                              epochs=5,\n",
    "                                              delta=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6f7cc",
   "metadata": {},
   "source": [
    "## Proceed with GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f2e1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 5ms/step\n",
      "1875/1875 [==============================] - 8s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "output_model_noise = DPmodel.predict(train_data)\n",
    "output_model_true = Normalmodel.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d821811b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1d_8\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Windows\\Temp\\ipykernel_34236\\3126455461.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdisc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminatortrue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_model_noise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdisc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_model_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_model_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Windows\\Temp\\ipykernel_34236\\2097253876.py\u001b[0m in \u001b[0;36mdiscriminator\u001b[1;34m(in_shape)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     model = tf.keras.Sequential([\n\u001b[0m\u001b[0;32m     53\u001b[0m         tf.keras.layers.Dense(in_shape*20,input_dim = in_shape,\n\u001b[0;32m     54\u001b[0m                               activation = 'relu'),\n",
      "\u001b[1;32mD:\\Sean\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Sean\\Miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Sean\\Miniconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[0;32m    229\u001b[0m                          \u001b[1;34m'is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                          \u001b[1;34mf'expected min_ndim={spec.min_ndim}, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv1d_8\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 200)"
     ]
    }
   ],
   "source": [
    "for i in range(0,6):\n",
    "    disc2 = discriminatortrue(output_model_noise.shape[1])\n",
    "    disc = discriminator(output_model_true.shape[1])\n",
    "    gen = generator(output_model_true.shape[1])\n",
    "    gan = GAN(gen,disc)\n",
    "    train(gen,disc,disc2,gan,output_model_noise,output_model_true,n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(output_model_noise.shape[0],output_model_noise.shape[1])\n",
    "noise = np.expand_dims(noise, axis=2)\n",
    "comparenoise = output_model_noise.flatten()\n",
    "comparetrue = output_model_true.flatten()\n",
    "comparefake = gen.predict(noise).flatten()\n",
    "sns.kdeplot(comparenoise)\n",
    "sns.kdeplot(comparetrue)\n",
    "plt.legend(labels = ['comparenoise','comparetrue'])\n",
    "plt.show()\n",
    "sns.kdeplot(comparefake)\n",
    "plt.legend(labels = 'comparefake')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(comparetrue,comparefake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(comparetrue)\n",
    "sns.kdeplot(comparefake)\n",
    "plt.legend(labels = ['comparetrue','comparefake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
